name: Performance Benchmarks

on:
  # Run on releases
  release:
    types: [published]
  # Manual trigger
  workflow_dispatch:
    inputs:
      save_baseline:
        description: 'Save results as new baseline'
        required: false
        default: 'false'
        type: boolean
  # Weekly check
  schedule:
    - cron: '0 10 * * 1'  # Monday 10am UTC

env:
  DEVELOPER_DIR: /Applications/Xcode.app/Contents/Developer

jobs:
  benchmark:
    name: Performance Benchmark
    runs-on: macos-14

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Select Xcode
        run: sudo xcode-select -s /Applications/Xcode.app

      - name: Install rclone
        run: brew install rclone

      - name: Cache DerivedData
        uses: actions/cache@v5
        with:
          path: ~/Library/Developer/Xcode/DerivedData
          key: deriveddata-perf-${{ runner.os }}-${{ hashFiles('**/*.swift') }}
          restore-keys: |
            deriveddata-perf-${{ runner.os }}-

      # Measure clean build time
      - name: Clean Build Benchmark
        id: build_time
        run: |
          echo "ðŸ—ï¸ Measuring clean build time..."

          # Clean
          xcodebuild clean -project CloudSyncApp.xcodeproj -scheme CloudSyncApp -quiet 2>/dev/null || true

          # Time the build
          START=$(date +%s)
          xcodebuild build \
            -project CloudSyncApp.xcodeproj \
            -scheme CloudSyncApp \
            -destination 'platform=macOS' \
            -quiet
          END=$(date +%s)

          BUILD_TIME=$((END - START))
          echo "build_time=$BUILD_TIME" >> $GITHUB_OUTPUT
          echo "âœ… Build completed in ${BUILD_TIME}s"

      # Run performance tests
      - name: Run Performance Tests
        id: perf_tests
        continue-on-error: true
        run: |
          echo "âš¡ Running performance tests..."

          xcodebuild test \
            -project CloudSyncApp.xcodeproj \
            -scheme CloudSyncApp \
            -destination 'platform=macOS' \
            -only-testing:CloudSyncAppTests/PerformanceTests \
            -resultBundlePath PerfResults \
            2>&1 | tee test_output.txt || true

          # Extract performance metrics from output
          grep -E "measured \[.*\] average:" test_output.txt > perf_metrics.txt || true

          if [ -s perf_metrics.txt ]; then
            echo "Found performance metrics:"
            cat perf_metrics.txt
            echo "perf_found=true" >> $GITHUB_OUTPUT
          else
            echo "No performance test metrics found"
            echo "perf_found=false" >> $GITHUB_OUTPUT
          fi

      # Check against baseline with regression detection
      - name: Check Performance Baseline
        id: baseline_check
        if: steps.perf_tests.outputs.perf_found == 'true'
        run: |
          BASELINE_FILE=".claude-team/metrics/perf-baseline.json"
          REGRESSION_THRESHOLD=20  # Alert on >20% regression
          HAS_REGRESSION=false

          echo "### Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "$BASELINE_FILE" ]; then
            echo "Comparing against baseline (regression threshold: ${REGRESSION_THRESHOLD}%)..." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Test | Measured (ms) | Baseline (ms) | Threshold (ms) | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|------|---------------|---------------|----------------|--------|" >> $GITHUB_STEP_SUMMARY

            # Parse and compare metrics against baseline
            while IFS= read -r line; do
              TEST_NAME=$(echo "$line" | grep -oE "test[A-Za-z_0-9]+" | head -1)
              # Extract average time in seconds, convert to ms
              AVG_TIME_SEC=$(echo "$line" | grep -oE "average: [0-9.]+" | sed 's/average: //')

              if [ -n "$TEST_NAME" ] && [ -n "$AVG_TIME_SEC" ]; then
                # Convert seconds to milliseconds (multiply by 1000)
                AVG_TIME_MS=$(echo "$AVG_TIME_SEC * 1000" | bc -l | xargs printf "%.1f")

                # Get baseline and threshold from JSON
                BASELINE_MS=$(jq -r ".baselines.\"$TEST_NAME\".average_ms // \"N/A\"" "$BASELINE_FILE")
                THRESHOLD_MS=$(jq -r ".baselines.\"$TEST_NAME\".threshold_ms // \"N/A\"" "$BASELINE_FILE")

                if [ "$BASELINE_MS" != "N/A" ] && [ "$THRESHOLD_MS" != "N/A" ]; then
                  # Check for regression (>20% above baseline)
                  REGRESSION_LIMIT=$(echo "$BASELINE_MS * (1 + $REGRESSION_THRESHOLD / 100)" | bc -l)

                  if (( $(echo "$AVG_TIME_MS > $THRESHOLD_MS" | bc -l) )); then
                    STATUS="FAIL - exceeds threshold"
                    HAS_REGRESSION=true
                  elif (( $(echo "$AVG_TIME_MS > $REGRESSION_LIMIT" | bc -l) )); then
                    STATUS="WARN - >20% regression"
                    HAS_REGRESSION=true
                  else
                    STATUS="PASS"
                  fi

                  echo "| $TEST_NAME | $AVG_TIME_MS | $BASELINE_MS | $THRESHOLD_MS | $STATUS |" >> $GITHUB_STEP_SUMMARY
                else
                  echo "| $TEST_NAME | $AVG_TIME_MS | N/A | N/A | No baseline |" >> $GITHUB_STEP_SUMMARY
                fi
              fi
            done < perf_metrics.txt

            echo "" >> $GITHUB_STEP_SUMMARY

            if [ "$HAS_REGRESSION" = true ]; then
              echo "regression_detected=true" >> $GITHUB_OUTPUT
              echo "::warning::Performance regression detected! One or more tests exceeded baseline by >20%"
              echo "**Warning: Performance regression detected!**" >> $GITHUB_STEP_SUMMARY
            else
              echo "regression_detected=false" >> $GITHUB_OUTPUT
              echo "All performance tests within acceptable limits." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "No baseline file found - establishing initial metrics" >> $GITHUB_STEP_SUMMARY
            echo "regression_detected=false" >> $GITHUB_OUTPUT
          fi

      # Alert on regression
      - name: Alert on Performance Regression
        if: steps.baseline_check.outputs.regression_detected == 'true'
        run: |
          echo "::error::Performance regression detected!"
          echo "One or more performance tests exceeded the 20% regression threshold."
          echo "Review the Performance Test Results in the workflow summary."
          # Fail the workflow on regression
          exit 1

      # Measure test execution time
      - name: Test Suite Benchmark
        id: test_time
        run: |
          echo "ðŸ§ª Measuring test execution time..."

          START=$(date +%s)
          xcodebuild test \
            -project CloudSyncApp.xcodeproj \
            -scheme CloudSyncApp \
            -destination 'platform=macOS' \
            -skip-testing:CloudSyncAppUITests \
            -quiet 2>&1 || true
          END=$(date +%s)

          TEST_TIME=$((END - START))
          echo "test_time=$TEST_TIME" >> $GITHUB_OUTPUT
          echo "âœ… Tests completed in ${TEST_TIME}s"

      # Compare with baseline
      - name: Compare with Baseline
        run: |
          BUILD_TIME=${{ steps.build_time.outputs.build_time }}
          TEST_TIME=${{ steps.test_time.outputs.test_time }}

          echo "### âš¡ Performance Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Time |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|------|" >> $GITHUB_STEP_SUMMARY
          echo "| Clean Build | ${BUILD_TIME}s |" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | ${TEST_TIME}s |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check for regressions (>20% slower than typical)
          if [ "$BUILD_TIME" -gt 120 ]; then
            echo "âš ï¸ **Warning:** Build time exceeds 2 minutes" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$TEST_TIME" -gt 60 ]; then
            echo "âš ï¸ **Warning:** Test time exceeds 1 minute" >> $GITHUB_STEP_SUMMARY
          fi

      # Save metrics artifact
      - name: Save Metrics
        run: |
          mkdir -p metrics
          cat > metrics/benchmark-$(date +%Y%m%d).json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "version": "$(cat VERSION.txt | tr -d '[:space:]')",
            "commit": "${{ github.sha }}",
            "build_time_seconds": ${{ steps.build_time.outputs.build_time }},
            "test_time_seconds": ${{ steps.test_time.outputs.test_time }}
          }
          EOF

      - name: Upload Metrics
        uses: actions/upload-artifact@v6
        with:
          name: performance-metrics
          path: metrics/
          retention-days: 90
